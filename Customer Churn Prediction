import pandas as pd 
import numpy as np 
import matplotlib.pyplot as plt
%matplotlib inline

-- (Importing the files)

data = pd.read_csv(r'C:/Users/raghv/Downloads/customer_churn.csv')

data.head()

# A) Data manipulation:
# a) Extract the 5th column & store it in ‘customer_5’.
customer_5 = data.iloc[:,4]
customer_5.head()

c=data.loc[:,'Dependents']
c.head()

#b.Extract the 15th column & store it in ‘customer_15’
customer_15= data.iloc[:,14]
customer_15.head()

#c.Extract all the male senior citizens whose Payment Method is Electronic check & store the result in ‘senior_male_electronic’

data['PaymentMethod'].value_counts()

senior_male_electronic= data[(data['gender']=='Male')& (data['SeniorCitizen']== 1) & (data['PaymentMethod']=='Electronic check')]
senior_male_electronic

senior_male_electronic.shape

#d.Extract all those customers whose tenure is greater than 70 months 'or' their Monthly charges is more than 100$ & store the result in ‘customer_total_tenure’

customer_total_tenure = data[(data['tenure']>70)|(data['MonthlyCharges']>100)]
customer_total_tenure

#e.Extract all the customers whose Contract is of two years, payment method is Mailed check & the value of Churn is ‘Yes’ & store the result in ‘two_mail_yes’

two_mail_yes= data[(data['Contract']=='Two year') & (data['PaymentMethod']=='Mailed check')& (data['Churn']=='Yes')]
two_mail_yes

#f.	Extract 333 random records from the customer_churn dataframe & store the result in ‘customer_333’
customer_333 = data.sample(n=333)
customer_333

#g.Get the count of different levels from the ‘Churn’ column.
data['Churn'].value_counts()

#B)Data Visualization:
#a.Build a bar-plot for the ’InternetService’ column:
#i.Set x-axis label to ‘Categories of Internet Service’
#ii.Set y-axis label to ‘Count of Categories’
#iii.Set the title of plot to be ‘Distribution of Internet Service’
#iv.Set the color of the bars to be ‘orange’

data['InternetService'].value_counts()

x =  data['InternetService'].value_counts().keys().tolist()
y =  data['InternetService'].value_counts().tolist()

y

plt.bar(x,y, color='orange')
plt.xlabel('catagories of Internet Services')
plt.ylabel('Count of cataories')
plt.title('Distribution of Internet services')

#b.	Build a histogram for the ‘tenure’ column:
#i.	Set the number of bins to be 30
#ii.	Set the color of the bins  to be ‘green’
#iii.	Assign the title ‘Distribution of tenure’

plt.hist(data['tenure'], color= 'green', bins=30)
plt.title('Distribution of Tenure')

#c.	Build a scatter-plot between ‘MonthlyCharges’ & ‘tenure’. Map ‘MonthlyCharges’ to the y-axis & ‘tenure’ to the ‘x-axis’:
#i.	Assign the points a color of ‘brown’
#ii.	Set the x-axis label to ‘Tenure of customer’
#iii.	Set the y-axis label to ‘Monthly Charges of customer’
#iv.	Set the title to ‘Tenure vs Monthly Charges’

plt.scatter(x=data['tenure'].head(20), y= data['MonthlyCharges'].head(20))
plt.xlabel('Tenure of customer')
plt.ylabel('Monthly Charges of customer')
plt.title('Tenure vs Monthly Charges')
plt.show()

#d.	Build a box-plot between ‘tenure’ & ‘Contract’. Map ‘tenure’ on the y-axis & ‘Contract’ on the x-axis. 

data.boxplot(column='tenure',by=['Contract'],figsize=(10,5))

#C)Linear Regression:
#a.Build a simple linear model where dependent variable is ‘MonthlyCharges’ and independent variable is ‘tenure’
#i.Divide the dataset into train and test sets in 70:30 ratio. 
#ii.Build the model on train set and predict the values on test set
#iii.After predicting the values, find the root mean square error
#iv.Find out the error in prediction & store the result in ‘error’
#v.Find the root mean square error

from sklearn import linear_model 
from sklearn.linear_model import LinearRegression
from sklearn.model_selection import train_test_split

y = data[['MonthlyCharges']]
x = data[['tenure']]

x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.30, random_state=0)

x_train.shape, x_test.shape, y_train.shape, y_test.shape

Lr = LinearRegression()
Lr.fit(x_train,y_train)

y_pred = Lr.predict(x_test)

from sklearn.metrics import mean_squared_error
np.sqrt(mean_squared_error(y_test,y_pred))

#D)	Logistic Regression:
#a.	Build a simple logistic regression model where dependent variable is ‘Churn’ & independent variable is ‘MonthlyCharges’
#i.	Divide the dataset in 65:35 ratio
#ii.	Build the model on train set and predict the values on test set
#iii.	Build the confusion matrix and get the accuracy score

x= data[['MonthlyCharges']]
y = data[['Churn']]

x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.35, random_state=0)

from sklearn.linear_model import LogisticRegression

log_model = LogisticRegression()

log_model.fit(x_train,y_train)

y_pred = log_model.predict(x_test)

from sklearn.metrics import confusion_matrix, accuracy_score

confusion_matrix(y_test,y_pred), accuracy_score(y_test,y_pred)

1815/(1815+651)

#b.Build a multiple logistic regression model where dependent variable is ‘Churn’ & independent variables are ‘tenure’ & ‘MonthlyCharges’
#i.Divide the dataset in 80:20 ratio
#ii.Build the model on train set and predict the values on test set
#iii.Build the confusion matrix and get the accuracy score

x= data[['MonthlyCharges', 'tenure']]
y = data[['Churn']]

x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.20, random_state=0)

from sklearn.linear_model import LogisticRegression

log_model = LogisticRegression()

log_model.fit(x_train,y_train)

y_pred = log_model.predict(x_test)

from sklearn.metrics import confusion_matrix, accuracy_score

confusion_matrix(y_test,y_pred), accuracy_score(y_test,y_pred)

(934+156)/(934+107+212+156)

#E)	Decision Tree:
#a.	Build a decision tree model where dependent variable is ‘Churn’ & independent variable is ‘tenure’
#i.	Divide the dataset in 80:20 ratio
#ii.	Build the model on train set and predict the values on test set
#iii.	Build the confusion matrix and calculate the accuracy

x= data[['tenure']]
y= data[['Churn']]

from sklearn.tree import DecisionTreeClassifier
x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.20, random_state=0)

my_tree = DecisionTreeClassifier()
my_tree.fit(x_train,y_train)

y_pred=my_tree.predict(x_test)

from sklearn.metrics import confusion_matrix, accuracy_score

confusion_matrix(y_test,y_pred), accuracy_score(y_test,y_pred)

confusion_matrix(y_test,y_pred)

(965+87)/(965+76+281+87)

from sklearn.ensemble import RandomForestClassifier

rf = RandomForestClassifier()

rf.fit(x_train,y_train)

y_pred= rf.predict(x_test)

confusion_matrix(y_test,y_pred), accuracy_score(y_test,y_pred)
